{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM tensorflow/tensorflow:2.0.0a0\n",
    "\n",
    "RUN pip install sagemaker-containers\n",
    "\n",
    "# Copies the training code inside the container\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "\n",
    "# Defines train.py as script entry point\n",
    "ENV SAGEMAKER_PROGRAM train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  40.96kB\n",
      "Step 1/5 : FROM tensorflow/tensorflow:2.0.0a0\n",
      " ---> 2ebc856b5e27\n",
      "Step 2/5 : RUN pip install sagemaker-containers\n",
      " ---> Using cache\n",
      " ---> 4cc501b79a04\n",
      "Step 3/5 : COPY train.py /opt/ml/code/train.py\n",
      " ---> b41a58676845\n",
      "Step 4/5 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code1\n",
      " ---> Running in b3ef3aaeeb13\n",
      "Removing intermediate container b3ef3aaeeb13\n",
      " ---> 66c77f6da09e\n",
      "Step 5/5 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 092af81eb191\n",
      "Removing intermediate container 092af81eb191\n",
      " ---> 20c54215d5a3\n",
      "Successfully built 20c54215d5a3\n",
      "Successfully tagged tf-2.0-with-lib:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t tf-2.0-with-lib ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmp1q2u1ljd_algo-1-tkilo_1 ... \n",
      "\u001b[1BAttaching to tmp1q2u1ljd_algo-1-tkilo_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:17,508 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:17,522 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:17,534 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:17,545 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"channel_input_dirs\": {}, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m             \"algo-1-tkilo\"\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m         ], \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m         \"current_host\": \"algo-1-tkilo\"\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     }, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"num_cpus\": 4, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"log_level\": 20, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"additional_framework_parameters\": {}, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m         \"algo-1-tkilo\"\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     ], \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"master_hostname\": \"algo-1-tkilo\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m         \"epochs\": 5, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m         \"other_para\": 0.1, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m         \"learning_rate\": 0.01, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m         \"batch_size\": 128\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     }, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"network_interface_name\": \"eth0\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"num_gpus\": 0, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"user_entry_point\": \"train.py\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"job_name\": \"tf-2.0-with-lib-2020-02-19-10-58-15-808\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"current_host\": \"algo-1-tkilo\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"is_master\": true, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"module_name\": \"train\", \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"input_data_config\": {}, \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m     \"framework_module\": null\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_HOSTS=[\"algo-1-tkilo\"]\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-tkilo\",\"framework_module\":null,\"hosts\":[\"algo-1-tkilo\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":5,\"learning_rate\":0.01,\"other_para\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-2.0-with-lib-2020-02-19-10-58-15-808\",\"log_level\":20,\"master_hostname\":\"algo-1-tkilo\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-tkilo\",\"hosts\":[\"algo-1-tkilo\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_HP_OTHER_PARA=0.1\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"5\",\"--learning_rate\",\"0.01\",\"--other_para\",\"0.1\"]\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_HP_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_HPS={\"batch_size\":128,\"epochs\":5,\"learning_rate\":0.01,\"other_para\":0.1}\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_HP_EPOCHS=5\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_HP_LEARNING_RATE=0.01\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-tkilo\",\"hosts\":[\"algo-1-tkilo\"]}\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python2.7:/usr/lib/python2.7/plat-x86_64-linux-gnu:/usr/lib/python2.7/lib-tk:/usr/lib/python2.7/lib-old:/usr/lib/python2.7/lib-dynload:/usr/local/lib/python2.7/dist-packages:/usr/lib/python2.7/dist-packages\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_CURRENT_HOST=algo-1-tkilo\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m /usr/bin/python train.py --batch_size 128 --epochs 5 --learning_rate 0.01 --other_para 0.1\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m \n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:19.405844: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:19.427797: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500000000 Hz\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:19.428157: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x5370c70 executing computations on platform Host. Devices:\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:19.428189: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2999 - accuracy: 0.9123\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.1438 - accuracy: 0.9593\n",
      "\u001b[36malgo-1-tkilo_1  |\u001b[0m 2020-02-19 10:58:23,358 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmp1q2u1ljd_algo-1-tkilo_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'epochs': 5, 'batch_size': 128, 'learning_rate': 0.01, 'other_para':0.1}\n",
    "\n",
    "estimator = Estimator(image_name='tf-2.0-with-lib',\n",
    "                      role=sagemaker.get_execution_role(),\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='local')\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM tensorflow/tensorflow:2.0.0a0\n",
    "\n",
    "# RUN pip install sagemaker-containers\n",
    "\n",
    "# Copies the training code inside the container\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "\n",
    "# Defines train.py as script entry point\n",
    "ENV SAGEMAKER_PROGRAM train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  41.47kB\n",
      "Step 1/3 : FROM tensorflow/tensorflow:2.0.0a0\n",
      " ---> 2ebc856b5e27\n",
      "Step 2/3 : COPY train.py /opt/ml/code/train.py\n",
      " ---> 33b8eb8101cc\n",
      "Step 3/3 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 66d88c5f8a02\n",
      "Removing intermediate container 66d88c5f8a02\n",
      " ---> d39487d0d8d2\n",
      "Successfully built d39487d0d8d2\n",
      "Successfully tagged tf-2.0-without-lib:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t tf-2.0-without-lib ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpsc_hp6h9_algo-1-2cplg_1 ... \n",
      "\u001b[1Bting tmpsc_hp6h9_algo-1-2cplg_1 ... \u001b[31merror\u001b[0m\n",
      "ERROR: for tmpsc_hp6h9_algo-1-2cplg_1  Cannot start service algo-1-2cplg: OCI runtime create failed: container_linux.go:345: starting container process caused \"exec: \\\"train\\\": executable file not found in $PATH\": unknown\n",
      "\n",
      "ERROR: for algo-1-2cplg  Cannot start service algo-1-2cplg: OCI runtime create failed: container_linux.go:345: starting container process caused \"exec: \\\"train\\\": executable file not found in $PATH\": unknown\n",
      "Encountered errors while bringing up the project.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/tmp/tmpsc_hp6h9/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6d1d38eb0897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                       train_instance_type='local')\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     def process(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtraining_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalTrainingJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmpsc_hp6h9/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'epochs': 5, 'batch_size': 128, 'learning_rate': 0.01, 'other_para':0.1}\n",
    "\n",
    "estimator = Estimator(image_name='tf-2.0-without-lib',\n",
    "                      role=sagemaker.get_execution_role(),\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='local')\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-dw4a3:\n",
      "    command: train\n",
      "    environment:\n",
      "    - AWS_REGION=us-east-2\n",
      "    - TRAINING_JOB_NAME=tf-2.0-without-lib-2020-02-19-08-13-15-912\n",
      "    image: tf-2.0-without-lib\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-dw4a3\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpdn05x743/algo-1-dw4a3/output:/opt/ml/output\n",
      "    - /tmp/tmpdn05x743/algo-1-dw4a3/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpdn05x743/algo-1-dw4a3/input:/opt/ml/input\n",
      "    - /tmp/tmpdn05x743/model:/opt/ml/model\n",
      "version: '2.3'\n"
     ]
    }
   ],
   "source": [
    "! cat /tmp/tmpdn05x743/docker-compose.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train1.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM tensorflow/tensorflow:2.0.0a0\n",
    "\n",
    "# RUN pip install sagemaker-containers\n",
    "\n",
    "# Copies the training code inside the container\n",
    "# train作为脚本将被之行\n",
    "COPY train1.py /opt/ml/code/train\n",
    "\n",
    "RUN chmod 777 /opt/ml/code/train\n",
    "\n",
    "# 将此目录添加到PATH中，因为sagemaker会之行docker run CONTAINER_ID train, train作为命令需要添加到PATH中\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "# 指定工作目录\n",
    "WORKDIR /opt/ml/code\n",
    "\n",
    "# Defines train.py as script entry point\n",
    "# 如果没有sagemaker-containers，这个环境变量没有用ENV SAGEMAKER_PROGRAM train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  40.96kB\n",
      "Step 1/5 : FROM tensorflow/tensorflow:2.0.0a0\n",
      " ---> 2ebc856b5e27\n",
      "Step 2/5 : COPY train1.py /opt/ml/code/train\n",
      " ---> Using cache\n",
      " ---> 77a7d58ad757\n",
      "Step 3/5 : RUN chmod 777 /opt/ml/code/train\n",
      " ---> Using cache\n",
      " ---> c4c6a9316d0b\n",
      "Step 4/5 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 5afe63d43b22\n",
      "Step 5/5 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 1f9e7dfef833\n",
      "Successfully built 1f9e7dfef833\n",
      "Successfully tagged tf-2.0-without-lib-fixed:latest\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "! docker build -t tf-2.0-without-lib-fixed ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmp20oye3fi_algo-1-3vg62_1 ... \n",
      "\u001b[1BAttaching to tmp20oye3fi_algo-1-3vg62_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m 2020-02-19 10:17:19.418049: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m 2020-02-19 10:17:19.439793: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500000000 Hz\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m 2020-02-19 10:17:19.440077: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x4c1ca90 executing computations on platform Host. Devices:\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m 2020-02-19 10:17:19.440105: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2952 - accuracy: 0.9142\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.1417 - accuracy: 0.9578\n",
      "\u001b[36mtmp20oye3fi_algo-1-3vg62_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'epochs': 5, 'batch_size': 128, 'learning_rate': 0.01, 'other_para':0.1}\n",
    "\n",
    "estimator = Estimator(image_name='tf-2.0-without-lib-fixed',\n",
    "                      role=sagemaker.get_execution_role(),\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='local')\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
