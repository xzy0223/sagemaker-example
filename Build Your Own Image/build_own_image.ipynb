{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6><center><big><b>适配你自己的训练镜像</b></big></center></font>\n",
    "\n",
    "通常客户都有自己的一套训练脚本或者训练容器，如果要集成到Sagemaker中，需要将您的训练脚本和容器按照Sagemaker的要求进行打包和修改。\n",
    "\n",
    "在本例中我们将阐述符合适配您现有的训练脚本到Sagemaker上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新建一个Hello World算法\n",
    "\n",
    "运行如下魔法命令，创建一个train.py训练脚本，我们稍后将把这个脚本打包进docker image中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建Dockerfile\n",
    "\n",
    "    我们从公共的docker hub上拉标准的tensorflow镜像，如果只是这样sagemaker是无法正常使用这个image进行训练的。我们需要在dockerfile中做三件事情\n",
    "- 安装sagemaker-training（以前叫sagemaker-containers）这个library，sagemaker会通过这个lib实现很多扩展的功能\n",
    "- copy训练脚本到容器的/opt/ml/code/路径下，这个是一个规定\n",
    "- 添加环境变量SAGEMAKER_PROGRAM，这个是告诉sagemaker你的训练入口在哪里，实际上获取这个环境变量并开启训练都是sagemaker-training完成的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM tensorflow/tensorflow:2.0.0a0\n",
    "\n",
    "RUN pip install sagemaker-training\n",
    "\n",
    "# Copies the training code inside the container\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "\n",
    "# Defines train.py as script entry point\n",
    "ENV SAGEMAKER_PROGRAM train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Image\n",
    "\n",
    "添加一个-lib的后缀，表示这个image是安装了sagemaker-training的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  80.38kB\n",
      "Step 1/4 : FROM tensorflow/tensorflow:2.0.0a0\n",
      "2.0.0a0: Pulling from tensorflow/tensorflow\n",
      "\n",
      "\u001b[1B2c1070cd: Pulling fs layer \n",
      "\u001b[1B74db61f1: Pulling fs layer \n",
      "\u001b[1Bcb72e5c9: Pulling fs layer \n",
      "\u001b[1B7a67709e: Pulling fs layer \n",
      "\u001b[2B7a67709e: Waiting fs layer \n",
      "\u001b[1B5d1c3937: Pulling fs layer \n",
      "\u001b[1Bc3f56b0a: Pulling fs layer \n",
      "\u001b[1B0fc18b45: Pulling fs layer \n",
      "\u001b[1B97d79d36: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:c51e5432db0faaca6a25025f8fbc29ee14b0b6bbb46ad4fd48e24a0901b9dde4[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[10A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[6A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[2A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\n",
      "Status: Downloaded newer image for tensorflow/tensorflow:2.0.0a0\n",
      " ---> 2ebc856b5e27\n",
      "Step 2/4 : RUN pip install sagemaker-training\n",
      " ---> Running in 04bbd3658571\n",
      "\u001b[91mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n",
      "\u001b[0mCollecting sagemaker-training\n",
      "  Downloading https://files.pythonhosted.org/packages/09/a2/d4fcce5a4350667a53f84077a2415709ca941d15a41c21f9cc5d20ad9528/sagemaker_training-3.6.2.tar.gz (40kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from sagemaker-training) (1.16.2)\n",
      "Collecting boto3 (from sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/b9/88fbe33f4f4862b06eed9e1fb05abb8883b0bf2683a87f21c45d597adc5a/boto3-1.15.17-py2.py3-none-any.whl (129kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from sagemaker-training) (1.12.0)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python2.7/dist-packages (from sagemaker-training) (19.0.3)\n",
      "Collecting retrying>=1.3.3 (from sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n",
      "Collecting gevent (from sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/df/d0fabd5113a91305896dbbc690a86d9bdb39b2032b8dfae64cd67d751642/gevent-20.9.0-cp27-cp27mu-manylinux2010_x86_64.whl (4.9MB)\n",
      "Collecting inotify_simple==1.2.1 (from sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/2d/c7450cc2c6ec9be3a6f35d7d22f6866f156a32f4ea97e75b13b27ad300fd/inotify_simple-1.2.1.tar.gz\n",
      "Collecting werkzeug>=0.15.5 (from sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n",
      "Collecting paramiko>=2.4.2 (from sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
      "Collecting psutil>=5.6.7 (from sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/aa/3e/d18f2c04cf2b528e18515999b0c8e698c136db78f62df34eee89cee205f1/psutil-5.7.2.tar.gz (460kB)\n",
      "Requirement already satisfied: protobuf>=3.1 in /usr/local/lib/python2.7/dist-packages (from sagemaker-training) (3.7.0)\n",
      "Collecting scipy>=1.2.2 (from sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/24/40/11b12af7f322c1e20446c037c47344d89bab4922b8859419d82cf56d796d/scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl (24.8MB)\n",
      "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from sagemaker-training) (1.1.6)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting botocore<1.19.0,>=1.18.17 (from boto3->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/12/6e/73f5a0c1041090589531d346d9310030a135b04cb0570d357da699a56a52/botocore-1.18.17-py2.py3-none-any.whl (6.7MB)\n",
      "Collecting greenlet>=0.4.17; platform_python_implementation == \"CPython\" (from gevent->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/d4/bbea0eee6bc1ee0aca4446934ab175c93638f326b56a682d8dc953f66d67/greenlet-0.4.17-cp27-cp27mu-manylinux1_x86_64.whl (42kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from gevent->sagemaker-training) (40.8.0)\n",
      "Collecting zope.event (from gevent->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
      "Collecting zope.interface (from gevent->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/c7/ee825596cfa42b6799bb72393de0059d14e3e40dabae9f701f0c6e2bcd10/zope.interface-5.1.2-cp27-cp27mu-manylinux2010_x86_64.whl (232kB)\n",
      "Collecting bcrypt>=3.1.3 (from paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/36/9a0227d048e98409f012570f7bef8a8c2373b9c9c5dfbf82963cbae05ede/bcrypt-3.1.7-cp27-cp27mu-manylinux1_x86_64.whl (59kB)\n",
      "Collecting pynacl>=1.0.1 (from paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/de/63/bb36279da38df643c6df3a8a389f29a6ff4a8854468f4c9b9d925b27d57d/PyNaCl-1.4.0-cp27-cp27mu-manylinux1_x86_64.whl (964kB)\n",
      "Collecting cryptography>=2.5 (from paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/b8/79858c68bafa7517c20859334ad270fe0c174a65c1ab80a9b8b377e7584b/cryptography-3.1.1-cp27-cp27mu-manylinux2010_x86_64.whl (2.6MB)\n",
      "Requirement already satisfied: futures<4.0.0,>=2.2.0; python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from s3transfer<0.4.0,>=0.3.0->boto3->sagemaker-training) (3.2.0)\n",
      "Collecting urllib3<1.26,>=1.20; python_version != \"3.4\" (from botocore<1.19.0,>=1.18.17->boto3->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl (127kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore<1.19.0,>=1.18.17->boto3->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting cffi>=1.1 (from bcrypt>=3.1.3->paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/98/76/90d154092a65911a386eb28fc0c6c65808d2d794d662b392cba236fec11e/cffi-1.14.3-cp27-cp27mu-manylinux1_x86_64.whl (388kB)\n",
      "Collecting ipaddress; python_version < \"3\" (from cryptography>=2.5->paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/f8/49697181b1651d8347d24c095ce46c7346c37335ddc7d255833e7cde674d/ipaddress-1.0.23-py2.py3-none-any.whl\n",
      "Collecting pycparser (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/e7/d9c3a176ca4b02024debf82342dab36efadfc5776f9c8db077e8f6e71821/pycparser-2.20-py2.py3-none-any.whl (112kB)\n",
      "Building wheels for collected packages: sagemaker-training, retrying, inotify-simple, psutil\n",
      "  Building wheel for sagemaker-training (setup.py): started\n",
      "  Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/10/36/7bee23f5f144051bf95bf515b36dd8579d3679ea7e83486494\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n",
      "  Building wheel for inotify-simple (setup.py): started\n",
      "  Building wheel for inotify-simple (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/77/f9/52cc89b27110b3fe0df40290275bd1151db9d0c7b15733cc3b\n",
      "  Building wheel for psutil (setup.py): started\n",
      "  Building wheel for psutil (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/a0/f5/c4fa280463e29aea07797acb5312358fefb067c1f4f98e11b1\n",
      "Successfully built sagemaker-training retrying inotify-simple psutil\n",
      "Installing collected packages: urllib3, jmespath, python-dateutil, botocore, s3transfer, boto3, retrying, greenlet, zope.event, zope.interface, gevent, inotify-simple, werkzeug, pycparser, cffi, bcrypt, pynacl, ipaddress, cryptography, paramiko, psutil, scipy, sagemaker-training\n",
      "  Found existing installation: Werkzeug 0.14.1\n",
      "    Uninstalling Werkzeug-0.14.1:\n",
      "      Successfully uninstalled Werkzeug-0.14.1\n",
      "Successfully installed bcrypt-3.1.7 boto3-1.15.17 botocore-1.18.17 cffi-1.14.3 cryptography-3.1.1 gevent-20.9.0 greenlet-0.4.17 inotify-simple-1.2.1 ipaddress-1.0.23 jmespath-0.10.0 paramiko-2.7.2 psutil-5.7.2 pycparser-2.20 pynacl-1.4.0 python-dateutil-2.8.1 retrying-1.3.3 s3transfer-0.3.3 sagemaker-training-3.6.2 scipy-1.2.3 urllib3-1.25.10 werkzeug-1.0.1 zope.event-4.5.0 zope.interface-5.1.2\n",
      "\u001b[91mYou are using pip version 19.0.3, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 04bbd3658571\n",
      " ---> 011e779efb03\n",
      "Step 3/4 : COPY train.py /opt/ml/code/train.py\n",
      " ---> 7d8811b26e31\n",
      "Step 4/4 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in fd909ba32a3c\n",
      "Removing intermediate container fd909ba32a3c\n",
      " ---> a9324505325b\n",
      "Successfully built a9324505325b\n",
      "Successfully tagged tf-2.0-with-lib:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t tf-2.0-with-lib ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行训练任务\n",
    "\n",
    "sagemaker可以直接从docker hub上拉镜像，所以需要在image_name参数中指定\n",
    "\n",
    "可以看到在这个运行的容器中，多了很多的环境变量，这些其实都是sagemaker-containers这个库做的事情，它会把这个job的一些info以环境变量的方式传递给容器，这样容器内的训练算法就可以直接使用这些环境变量，另外在下边可以看到训练入口的train.py，它是如何实际执行的：\n",
    "\n",
    "/usr/bin/python train.py --batch_size 128 --epochs 5 --learning_rate 0.01 --other_para 0.1\n",
    "\n",
    "可以看到这里sagemaker-training把超参数以参数的形式传递给了训练脚本，这样就可以在脚本内部通过argparse解析这些超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpnjz5duxl_algo-1-90j4h_1 ... \n",
      "\u001b[1BAttaching to tmpnjz5duxl_algo-1-90j4h_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m /usr/local/lib/python2.7/dist-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in a future release.\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m   from cryptography.hazmat.backends import default_backend\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:45,716 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:45,728 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:45,740 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:45,749 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"channel_input_dirs\": {}, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m             \"algo-1-90j4h\"\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m         ], \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m         \"current_host\": \"algo-1-90j4h\"\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     }, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"num_cpus\": 4, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"log_level\": 20, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"additional_framework_parameters\": {}, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m         \"algo-1-90j4h\"\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     ], \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"master_hostname\": \"algo-1-90j4h\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m         \"epochs\": 5, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m         \"other_para\": 0.1, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m         \"learning_rate\": 0.01, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m         \"batch_size\": 128\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     }, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"network_interface_name\": \"eth0\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"num_gpus\": 0, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"user_entry_point\": \"train.py\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"job_name\": \"tf-2.0-with-lib-2020-10-16-15-38-44-256\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"current_host\": \"algo-1-90j4h\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"is_master\": true, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"module_name\": \"train\", \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"input_data_config\": {}, \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m     \"framework_module\": null\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_HOSTS=[\"algo-1-90j4h\"]\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-90j4h\",\"framework_module\":null,\"hosts\":[\"algo-1-90j4h\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":5,\"learning_rate\":0.01,\"other_para\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-2.0-with-lib-2020-10-16-15-38-44-256\",\"log_level\":20,\"master_hostname\":\"algo-1-90j4h\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-90j4h\",\"hosts\":[\"algo-1-90j4h\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_HP_OTHER_PARA=0.1\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"5\",\"--learning_rate\",\"0.01\",\"--other_para\",\"0.1\"]\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_HP_BATCH_SIZE=128\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_HPS={\"batch_size\":128,\"epochs\":5,\"learning_rate\":0.01,\"other_para\":0.1}\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_HP_EPOCHS=5\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_HP_LEARNING_RATE=0.01\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-90j4h\",\"hosts\":[\"algo-1-90j4h\"]}\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python2.7:/usr/lib/python2.7/plat-x86_64-linux-gnu:/usr/lib/python2.7/lib-tk:/usr/lib/python2.7/lib-old:/usr/lib/python2.7/lib-dynload:/usr/local/lib/python2.7/dist-packages:/usr/lib/python2.7/dist-packages\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_CURRENT_HOST=algo-1-90j4h\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m /usr/bin/python train.py --batch_size 128 --epochs 5 --learning_rate 0.01 --other_para 0.1\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m \n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:47.608208: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:47.630536: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500000000 Hz\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:47.630926: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x49b2920 executing computations on platform Host. Devices:\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:47.630964: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2916 - accuracy: 0.9158\n",
      "10000/10000 [==============================] - 0s 29us/sample - loss: 0.1357 - accuracy: 0.9606\n",
      "\u001b[36malgo-1-90j4h_1  |\u001b[0m 2020-10-16 15:38:51,567 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpnjz5duxl_algo-1-90j4h_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'epochs': 5, 'batch_size': 128, 'learning_rate': 0.01, 'other_para':0.1}\n",
    "\n",
    "estimator = Estimator(image_name='tf-2.0-with-lib',\n",
    "                      role=sagemaker.get_execution_role(),\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='local')\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩展问题：如果不装sagemaker-containers会怎样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM tensorflow/tensorflow:2.0.0a0\n",
    "\n",
    "# RUN pip install sagemaker-training\n",
    "\n",
    "# Copies the training code inside the container\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "\n",
    "# Defines train.py as script entry point\n",
    "ENV SAGEMAKER_PROGRAM train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  96.26kB\n",
      "Step 1/3 : FROM tensorflow/tensorflow:2.0.0a0\n",
      " ---> 2ebc856b5e27\n",
      "Step 2/3 : COPY train.py /opt/ml/code/train.py\n",
      " ---> 50103b4804b6\n",
      "Step 3/3 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 1d4f7d39db9f\n",
      "Removing intermediate container 1d4f7d39db9f\n",
      " ---> 9931a95f9000\n",
      "Successfully built 9931a95f9000\n",
      "Successfully tagged tf-2.0-without-lib:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t tf-2.0-without-lib ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 答案是：任务失败\n",
    "\n",
    "因为没有sagemaker-training，所以docker无法找到训练入口，及时您指定了环境变量也不能被感知到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpsc_hp6h9_algo-1-2cplg_1 ... \n",
      "\u001b[1Bting tmpsc_hp6h9_algo-1-2cplg_1 ... \u001b[31merror\u001b[0m\n",
      "ERROR: for tmpsc_hp6h9_algo-1-2cplg_1  Cannot start service algo-1-2cplg: OCI runtime create failed: container_linux.go:345: starting container process caused \"exec: \\\"train\\\": executable file not found in $PATH\": unknown\n",
      "\n",
      "ERROR: for algo-1-2cplg  Cannot start service algo-1-2cplg: OCI runtime create failed: container_linux.go:345: starting container process caused \"exec: \\\"train\\\": executable file not found in $PATH\": unknown\n",
      "Encountered errors while bringing up the project.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/tmp/tmpsc_hp6h9/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6d1d38eb0897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                       train_instance_type='local')\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     def process(\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtraining_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalTrainingJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmpsc_hp6h9/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'epochs': 5, 'batch_size': 128, 'learning_rate': 0.01, 'other_para':0.1}\n",
    "\n",
    "estimator = Estimator(image_name='tf-2.0-without-lib',\n",
    "                      role=sagemaker.get_execution_role(),\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='local')\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上面这个例子，我在Dockerfile中不安装sagemaker-containers，运行训练任务就回报错，另外在报错中找到了一条有用的信息：\n",
    "原来sagemaker是通过docker compose进行调度的 ['docker-compose', '-f', '/tmp/tmpsc_hp6h9/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit']\n",
    "\n",
    "我们查看一下这个文件，实际上要在容器中执行train命令，而如果没有安装sagemaker-training，那么是没有这个入口脚本的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-dw4a3:\n",
      "    command: train\n",
      "    environment:\n",
      "    - AWS_REGION=us-east-2\n",
      "    - TRAINING_JOB_NAME=tf-2.0-without-lib-2020-02-19-08-13-15-912\n",
      "    image: tf-2.0-without-lib\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-dw4a3\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpdn05x743/algo-1-dw4a3/output:/opt/ml/output\n",
      "    - /tmp/tmpdn05x743/algo-1-dw4a3/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpdn05x743/algo-1-dw4a3/input:/opt/ml/input\n",
      "    - /tmp/tmpdn05x743/model:/opt/ml/model\n",
      "version: '2.3'\n"
     ]
    }
   ],
   "source": [
    "! cat /tmp/tmpdn05x743/docker-compose.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩展问题：如果我不想安装sagemaker-training，还可以使用Sagemaker训练吗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train1.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然我们知道Sagemaker会调用容器的train命令，那么我只要把训练脚本的名字设置为‘train’，并且将脚本所在的路径加入到PATH就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM tensorflow/tensorflow:2.0.0a0\n",
    "\n",
    "# RUN pip install sagemaker-containers\n",
    "\n",
    "# Copies the training code inside the container\n",
    "# train作为脚本将被执行\n",
    "COPY train1.py /opt/ml/code/train\n",
    "\n",
    "RUN chmod 777 /opt/ml/code/train\n",
    "\n",
    "# 将此目录添加到PATH中，因为sagemaker会之行docker run CONTAINER_ID train, train作为命令需要添加到PATH中\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "# 指定工作目录\n",
    "WORKDIR /opt/ml/code\n",
    "\n",
    "# Defines train.py as script entry point\n",
    "# 如果没有sagemaker-containers，这个环境变量没有用ENV SAGEMAKER_PROGRAM train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  40.96kB\n",
      "Step 1/5 : FROM tensorflow/tensorflow:2.0.0a0\n",
      " ---> 2ebc856b5e27\n",
      "Step 2/5 : COPY train1.py /opt/ml/code/train\n",
      " ---> Using cache\n",
      " ---> 77a7d58ad757\n",
      "Step 3/5 : RUN chmod 777 /opt/ml/code/train\n",
      " ---> Using cache\n",
      " ---> c4c6a9316d0b\n",
      "Step 4/5 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 5afe63d43b22\n",
      "Step 5/5 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> 1f9e7dfef833\n",
      "Successfully built 1f9e7dfef833\n",
      "Successfully tagged tf-2.0-without-lib-fixed:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t tf-2.0-without-lib-fixed ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 答案是：可以\n",
    "\n",
    "但是很多功能是缺失的，比如看不到更多的sagamaker吐出的信息，很多配置不会被配置成容器内的环境变量等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmp20oye3fi_algo-1-3vg62_1 ... \n",
      "\u001b[1BAttaching to tmp20oye3fi_algo-1-3vg62_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m 2020-02-19 10:17:19.418049: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m 2020-02-19 10:17:19.439793: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500000000 Hz\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m 2020-02-19 10:17:19.440077: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x4c1ca90 executing computations on platform Host. Devices:\n",
      "\u001b[36malgo-1-3vg62_1  |\u001b[0m 2020-02-19 10:17:19.440105: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2952 - accuracy: 0.9142\n",
      "10000/10000 [==============================] - 0s 30us/sample - loss: 0.1417 - accuracy: 0.9578\n",
      "\u001b[36mtmp20oye3fi_algo-1-3vg62_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "hyperparameters = {'epochs': 5, 'batch_size': 128, 'learning_rate': 0.01, 'other_para':0.1}\n",
    "\n",
    "estimator = Estimator(image_name='tf-2.0-without-lib-fixed',\n",
    "                      role=sagemaker.get_execution_role(),\n",
    "                      hyperparameters=hyperparameters,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='local')\n",
    "\n",
    "estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
