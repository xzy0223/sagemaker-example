{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, optimizers, layers, metrics, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现自定义的layer，需要继承自layers.Layer\n",
    "class MyDense(layers.Layer):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        # 初始化w和b，使用Layer已经实现的add_weight方法初始化w和b参数\n",
    "        self.kernel = self.add_weight('w', [input_dim, output_dim])\n",
    "        self.bias = self.add_weight('b', [output_dim])\n",
    "    # 调用mydense(x) ==> mydense.__call__(x) ==> mydense.call(x)\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs @ self.kernel + self.bias  # 定义每层的线性层的计算\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现自定义的Model，继承自keras.Model\n",
    "class MyModel(keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 定义model的各个层\n",
    "        self.fc1 = MyDense(32*32*3, 256)\n",
    "        self.fc2 = MyDense(256, 128)\n",
    "        self.fc3 = MyDense(128, 64)\n",
    "        self.fc4 = MyDense(64, 32)\n",
    "        self.fc5 = MyDense(32, 10)\n",
    "    # 调用mymodel(x) ==> mymodel.__call__(x) ==> mymodel.call(x)\n",
    "    # 定义网络前向传播的方式\n",
    "    def call(self, inputs, training=None):\n",
    "        \n",
    "        x = tf.reshape(inputs, [-1, 32*32*3])\n",
    "        # [b, 32*32*3] => [b, 256]\n",
    "        x = tf.nn.relu(self.fc1(x))\n",
    "        # [b, 256] => [b, 128]\n",
    "        x = tf.nn.relu(self.fc2(x))\n",
    "        # [b, 128] => [b, 64]\n",
    "        x = tf.nn.relu(self.fc3(x))\n",
    "        # [b, 64] => [b, 32]\n",
    "        x = tf.nn.relu(self.fc4(x))\n",
    "        # [b, 32] => [b, 10]\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "def process(x, y):\n",
    "    \n",
    "    x = 2 * tf.cast(x, dtype=tf.float32) / 255. - 1  # 对于cifar10的数据来说，把数据归一化到-1到1之间可以得到更好的训练效果\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.squeeze(y)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_db = train_db.map(process).shuffle(10000).batch(128)\n",
    "test_db = test_db.map(process).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建自定义的Model\n",
    "network = MyModel()\n",
    "# 组织网络的组建，由于继承自keras.Model，所以可以使用compile方法\n",
    "network.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "                         loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 1.7167 - accuracy: 0.3896197 - accuracy: 0.38 - 7s 19ms/step - loss:\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1.4970 - accuracy: 0.4700\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1.3872 - accuracy: 0.5135\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1.3066 - accuracy: 0.5413\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 1.2367 - accuracy: 0.5642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7b17140048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "# 对于训练结果，可以增加epoch提高性能，但是天花板就在那里\n",
    "# 此外还可以增加每层的参数量提高模型的复杂度，但是容易出现过拟合的现象\n",
    "# 还可以调整x的归一化形式，在process函数中调整\n",
    "network.fit(train_db, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 19ms/step - loss: 1.3888 - accuracy: 0.5127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3888207191153417, 0.5127]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估模型\n",
    "network.evaluate(test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存所有的训练参数到checkpoint文件中\n",
    "network.save_weights('ckpt/weights.ckpt')\n",
    "# 删除model\n",
    "del network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 19ms/step - loss: 1.3963 - accuracy: 0.5070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3963348352456395, 0.507]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用这种方法保存的model，需要重建一个一模一样的network，然后把参数load进来\n",
    "network = MyModel()\n",
    "network.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "                         loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "network.load_weights('ckpt/weights.ckpt')\n",
    "# eval的结果和刚才的model一样\n",
    "network.evaluate(test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_mode/assets\n"
     ]
    }
   ],
   "source": [
    "# 或者使用这个方法，直接保存整个网络到一个通用文件中，可用于在其他地方部署，使用tensor serving可以加载这个model\n",
    "tf.saved_model.save(network, 'saved_mode/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载model\n",
    "imported = tf.saved_model.load('saved_mode/')\n",
    "# 返回一个可被调用的对象\n",
    "predictor = imported.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_1': <tf.Tensor: id=35111, shape=(1, 10), dtype=float32, numpy=\n",
       " array([[ 1.7184494 , -7.043526  , -0.38373035,  0.98874104, -2.973388  ,\n",
       "          0.6442143 , -5.308611  , -2.715285  , -1.3639593 , -5.4435244 ]],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟一组数据进行预测\n",
    "predictor(tf.ones([32,32,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-053cb14e6118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \"\"\"\n\u001b[1;32m    974\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m--> 975\u001b[0;31m                       signatures, options)\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    103\u001b[0m         not isinstance(model, sequential.Sequential)):\n\u001b[1;32m    104\u001b[0m       raise NotImplementedError(\n\u001b[0;32m--> 105\u001b[0;31m           \u001b[0;34m'Saving the model to HDF5 format requires the model to be a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m           \u001b[0;34m'Functional model or a Sequential model. It does not work for '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m           \u001b[0;34m'subclassed models, because such models are defined via the body of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "# 如果是keras.Model的子类的化，是不能直接保存为h5类型的\n",
    "network.save('saved_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
